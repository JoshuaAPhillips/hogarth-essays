{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates over .txt and breaks into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\u001b[1;31m  File \"/Users/Joshua/Library/CloudStorage/OneDrive-Nexus365/Articles and Publications/In Progress/MAPP FMS Takeover - Hogarth Essays/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "\u001b[1;31m    from ipykernel import kernelapp as app\n",
      "\u001b[1;31m  File \"/Users/Joshua/Library/CloudStorage/OneDrive-Nexus365/Articles and Publications/In Progress/MAPP FMS Takeover - Hogarth Essays/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 21, in <module>\n",
      "\u001b[1;31m    from IPython.core.application import (  # type:ignore[attr-defined]\n",
      "\u001b[1;31m  File \"/Users/Joshua/Library/CloudStorage/OneDrive-Nexus365/Articles and Publications/In Progress/MAPP FMS Takeover - Hogarth Essays/venv/lib/python3.11/site-packages/IPython/__init__.py\", line 55, in <module>\n",
      "\u001b[1;31m    from .terminal.embed import embed\n",
      "\u001b[1;31m  File \"/Users/Joshua/Library/CloudStorage/OneDrive-Nexus365/Articles and Publications/In Progress/MAPP FMS Takeover - Hogarth Essays/venv/lib/python3.11/site-packages/IPython/terminal/embed.py\", line 15, in <module>\n",
      "\u001b[1;31m    from IPython.core.interactiveshell import DummyMod, InteractiveShell\n",
      "\u001b[1;31m  File \"/Users/Joshua/Library/CloudStorage/OneDrive-Nexus365/Articles and Publications/In Progress/MAPP FMS Takeover - Hogarth Essays/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 110, in <module>\n",
      "\u001b[1;31m    from IPython.core.history import HistoryManager\n",
      "\u001b[1;31m  File \"/Users/Joshua/Library/CloudStorage/OneDrive-Nexus365/Articles and Publications/In Progress/MAPP FMS Takeover - Hogarth Essays/venv/lib/python3.11/site-packages/IPython/core/history.py\", line 10, in <module>\n",
      "\u001b[1;31m    import sqlite3\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.11/sqlite3/__init__.py\", line 57, in <module>\n",
      "\u001b[1;31m    from sqlite3.dbapi2 import *\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.11/sqlite3/dbapi2.py\", line 27, in <module>\n",
      "\u001b[1;31m    from _sqlite3 import *\n",
      "\u001b[1;31mImportError: dlopen(/opt/anaconda3/lib/python3.11/lib-dynload/_sqlite3.cpython-311-darwin.so, 0x0002): Symbol not found: _sqlite3_enable_load_extension\n",
      "\u001b[1;31m  Referenced from: <70F1DCE8-3D0F-3766-9D17-14201FC080E6> /opt/anaconda3/lib/python3.11/lib-dynload/_sqlite3.cpython-311-darwin.so\n",
      "\u001b[1;31m  Expected in:     <2F5BE899-2B4C-330F-B593-E71E5C0D2958> /usr/lib/libsqlite3.dylib. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_words=250):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), max_words):\n",
    "        yield ' '.join(words[i:i + max_words])\n",
    "\n",
    "def process_file(file_path, output_writer, doc_id):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "    # Split the content into paragraphs\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', content)\n",
    "    \n",
    "    # Write each paragraph as a separate row (or rows) in the TSV\n",
    "    for i, paragraph in enumerate(paragraphs):\n",
    "        # Remove any newlines within the paragraph\n",
    "        paragraph = paragraph.replace('\\n', ' ').strip()\n",
    "        if paragraph:  # Only process non-empty paragraphs\n",
    "            # Split paragraph into chunks of max 250 words\n",
    "            for j, chunk in enumerate(split_text(paragraph)):\n",
    "                output_writer.writerow([f\"{doc_id}_{i}_{j}\", \"TAG\", chunk])\n",
    "\n",
    "def process_directory(input_dir, output_file):\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as tsv_file:\n",
    "        writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writerow([\"ID\", \"TAG\", \"TEXT\"])\n",
    "        \n",
    "        # Process each .txt file in the directory\n",
    "        for i, filename in enumerate(os.listdir(input_dir)):\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(input_dir, filename)\n",
    "                process_file(file_path, writer, f\"doc_{i}\")\n",
    "\n",
    "# Usage\n",
    "input_directory = './scans/text'\n",
    "output_tsv = 'output_for_mallet.tsv'\n",
    "process_directory(input_directory, output_tsv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
